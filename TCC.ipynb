{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Procedimentos para baixar os arquivos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import os\r\n",
    "import zipfile\r\n",
    "\r\n",
    "# Faz o download dos arquivos conforme a url fornecida e o coloca no endereço do segundo parâmetro\r\n",
    "def baixar_arquivo(url, endereco=None):\r\n",
    "    if endereco is None:\r\n",
    "        endereco = os.path.basename(url.split(\"?\")[0])\r\n",
    "    resposta = requests.get(url, stream=True)\r\n",
    "    if resposta.status_code == requests.codes.OK:\r\n",
    "        with open(endereco, 'wb') as novo_arquivo:\r\n",
    "            for parte in resposta.iter_content(chunk_size=256):\r\n",
    "                novo_arquivo.write(parte)\r\n",
    "        print(\"Download finalizado. Arquivo salvo em: {}\".format(endereco))\r\n",
    "    else:\r\n",
    "        resposta.raise_for_status()\r\n",
    "\r\n",
    "\r\n",
    "# Seleciona os arquivos a serem baixados do site de dados abertos da ANP\r\n",
    "def selecionar_arquivos_fiscalizacao_para_baixar():\r\n",
    "    # Ações de fiscalização de 2019\r\n",
    "    metadados_fiscalizacao = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/arquivos-acoes-de-fiscalizacao/acoes-de-fiscalizacao-metadados.pdf\"\r\n",
    "    fiscalizacao = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/arquivos-acoes-de-fiscalizacao/acoes-de-fiscalizacao.csv\"\r\n",
    "\r\n",
    "    # cria o diretorio, caso não exista\r\n",
    "    if not os.path.exists(\"dados\\\\fiscalizacoes\\\\\"):\r\n",
    "        os.makedirs(\"dados\\\\fiscalizacoes\\\\\")\r\n",
    "\r\n",
    "    print(\"Baixando metadados das ações de fiscalização de 2019\")\r\n",
    "    baixar_arquivo(metadados_fiscalizacao, \"dados\\\\fiscalizacoes\\\\acoes-de-fiscalizacao-metadados.pdf\")\r\n",
    "\r\n",
    "    print(\"Baixando acoes de fiscalizacao de 2019\")\r\n",
    "    baixar_arquivo(fiscalizacao, \"dados\\\\fiscalizacoes\\\\acoes-de-fiscalizacao.csv\")\r\n",
    "\r\n",
    "\r\n",
    "# Como estes arquivos são atualizados com uma certa frequencia, teremos sempre os dados mais atualizados\r\n",
    "def selecionar_arquivos_serie_historica_para_baixar():\r\n",
    "    # Série histórica de preços de combustíveis - revenda -  2019\r\n",
    "    metadados_serie_historica = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/shpc/metadados-levantamento-precos.pdf\"\r\n",
    "    serie_1_sem_2019 = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/shpc/dsas/ca/ca-2019-01.csv\"\r\n",
    "    serie_2_sem_2019 = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/shpc/dsas/ca/ca-2019-02.csv\"\r\n",
    "\r\n",
    "    # cria o diretorio, caso não exista\r\n",
    "    if not os.path.exists(\"dados\\\\serie\\\\\"):\r\n",
    "        os.makedirs(\"dados\\\\serie\\\\\")\r\n",
    "\r\n",
    "    print(\"Baixando metadados da série histórica do primeiro semestre de 2019\")\r\n",
    "    baixar_arquivo(metadados_serie_historica, \"dados\\serie\\metadados_serie_historica.pdf\")\r\n",
    "\r\n",
    "    print(\"Baixando série histórica do primeiro semestre de 2019\")\r\n",
    "    baixar_arquivo(serie_1_sem_2019, \"dados\\serie\\sem_2019-1_CA.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando série histórica do segundo semestre de 2019\")\r\n",
    "    baixar_arquivo(serie_2_sem_2019, \"dados\\serie\\sem_2019-2_CA.csv\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def selecionar_arquivos_multas_para_baixar():\r\n",
    "    # multas aplicadas pela anp entre 2016 e 2019\r\n",
    "    metadados_multas_aplicadas_2016_a_2019 = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/mav/metadados-multas-aplicadas-2016a2019.pdf\"\r\n",
    "    multas_2016_a_2019 = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/mav/multas-aplicadas-2016a2019.csv\"\r\n",
    "    \r\n",
    "    # cria o diretorio, caso não exista\r\n",
    "    if not os.path.exists(\"dados\\\\multas\\\\\"):\r\n",
    "        os.makedirs(\"dados\\\\multas\\\\\")\r\n",
    "\r\n",
    "    print(\"Baixando metadados multas aplicadas entre 2016 e 2019\")\r\n",
    "    baixar_arquivo(metadados_multas_aplicadas_2016_a_2019, \"dados\\multas\\metadados_multas_aplicadas_2016_a_2019.pdf\")\r\n",
    "    \r\n",
    "    print(\"Baixando multas aplicadas entre 2016 e 2019\")\r\n",
    "    baixar_arquivo(multas_2016_a_2019, \"dados\\multas\\multas_2016_a_2019.csv\")\r\n",
    "\r\n",
    "\r\n",
    "def selecionar_arquivos_reclamacoes_para_baixar():\r\n",
    "    # Reclamações registradas nos PROCONS – Sindec\r\n",
    "    metadados_reclamacoes = \"http://dados.mj.gov.br/dataset/8ff7032a-d6db-452b-89f1-d860eb6965ff/resource/d87543d6-cf9d-4752-8f3c-1b0aa075dc45/download/dicionariodadossindec3-0.pdf\"\r\n",
    "    reclamacoes = \"http://dados.mj.gov.br/dataset/8ff7032a-d6db-452b-89f1-d860eb6965ff/resource/c2cce323-24c2-4430-8918-e24b2966213c/download/crf2019-dados-abertos.zip\"\r\n",
    "    \r\n",
    "    # cria o diretorio, caso não exista\r\n",
    "    if not os.path.exists(\"dados\\\\reclamacoes\\\\\"):\r\n",
    "        os.makedirs(\"dados\\\\reclamacoes\\\\\")\r\n",
    "\r\n",
    "    print(\"Baixando metadados de reclamacoes\")\r\n",
    "    baixar_arquivo(metadados_reclamacoes, \"dados\\\\reclamacoes\\\\metadados_reclamacoes.pdf\")\r\n",
    "    \r\n",
    "    print(\"Baixando dados de reclamacoes\")\r\n",
    "    baixar_arquivo(reclamacoes, \"dados\\\\reclamacoes\\\\crf2019-dados-abertos.zip\")\r\n",
    "\r\n",
    "    print(\"Extraindo dados de reclamacoes do arquivo zip\")\r\n",
    "    with zipfile.ZipFile(\"dados\\\\reclamacoes\\\\crf2019-dados-abertos.zip\", 'r') as zip_ref:\r\n",
    "        zip_ref.extractall(\"dados\\\\reclamacoes\\\\\")\r\n",
    "\r\n",
    "\r\n",
    "def selecionar_arquivos_PMQC_para_baixar():    \r\n",
    "    # dados do programa de qualidade de 2019\r\n",
    "    metadados_PMQC = \"https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/pmqc/pmqc-metadados.pdf\"\r\n",
    " \r\n",
    "    PMQC_2019_01 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/PMQC_2019_01.csv\"\r\n",
    "    PMQC_2019_02 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/PMQC_2019_02.csv\"\r\n",
    "    PMQC_2019_03 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/PMQC_2019_03.csv\"\r\n",
    "    PMQC_2019_04 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-04-pmqc.csv\"\r\n",
    "    PMQC_2019_05 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-05-pmqc.csv\"\r\n",
    "    PMQC_2019_06 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-06-pmqc.csv\"\r\n",
    "    PMQC_2019_07 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-07-pmqc.csv\"\r\n",
    "    PMQC_2019_08 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-08-pmqc.csv\"\r\n",
    "    PMQC_2019_09 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-09-pmqc.csv\"\r\n",
    "    PMQC_2019_10 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-10-pmqc.csv\"\r\n",
    "    PMQC_2019_11 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-11-pmqc.csv\"\r\n",
    "    PMQC_2019_12 = \"http://www.anp.gov.br/arquivos/dadosabertos/PMQC/2019-12-pmqc.csv\"\r\n",
    "\r\n",
    "    # cria o diretorio, caso não exista\r\n",
    "    if not os.path.exists(\"dados\\\\PMQC\\\\\"):\r\n",
    "        os.makedirs(\"dados\\\\PMQC\\\\\")\r\n",
    "\r\n",
    "    print(\"Baixando metadado PMQC - Programa de Monitoramento da Qualidade dos Combustíveis\")\r\n",
    "    baixar_arquivo(metadados_PMQC, \"dados\\PMQC\\PMQC_metadados.pdf\")\r\n",
    " \r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Janeiro de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_01, \"dados\\PMQC\\PMQC_2019_01.csv\")\r\n",
    "    \r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Fevereiro de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_02, \"dados\\PMQC\\PMQC_2019_02.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Março de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_03, \"dados\\PMQC\\PMQC_2019_03.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Abril de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_04, \"dados\\PMQC\\PMQC_2019_04.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Maio de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_05, \"dados\\PMQC\\PMQC_2019_05.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Junho de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_06, \"dados\\PMQC\\PMQC_2019_06.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Julho de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_07, \"dados\\PMQC\\PMQC_2019_07.csv\")\r\n",
    "    \r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Agosto de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_08, \"dados\\PMQC\\PMQC_2019_08.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Setembro de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_09, \"dados\\PMQC\\PMQC_2019_09.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Outubro de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_10, \"dados\\PMQC\\PMQC_2019_10.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Novembro de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_11, \"dados\\PMQC\\PMQC_2019_11.csv\")\r\n",
    "\r\n",
    "    print(\"Baixando PMQC - Programa de Monitoramento da Qualidade dos Combustíveis - Dezembro de 2019\")\r\n",
    "    baixar_arquivo(PMQC_2019_12, \"dados\\PMQC\\PMQC_2019_12.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baixa os arquivos usando os procedimentos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#selecionar_arquivos_serie_historica_para_baixar()\r\n",
    "#selecionar_arquivos_multas_para_baixar()\r\n",
    "#selecionar_arquivos_reclamacoes_para_baixar()\r\n",
    "#selecionar_arquivos_PMQC_para_baixar()\r\n",
    "#selecionar_arquivos_fiscalizacao_para_baixar()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Procedimentos para carregar os arquivos baixados nos dataframes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import glob\r\n",
    "\r\n",
    "# carrega os dados de da série histórica do primeiro e segundo semestres de 2019 no dataframe\r\n",
    "# Foi incluido o parâmetro , skipinitialspace=True para retirar os espaço em branco antes dos valores das colunas (Principalmente CNPJ)\r\n",
    "def carregar_dados_serie_historica_2019():\r\n",
    "    df_serie_primeiro_sem_2019 = pd.read_csv(\"dados\\serie\\sem_2019-1_CA.csv\", encoding=\"UTF-8\", sep=\";\", skipinitialspace=True)\r\n",
    "    df_serie_segundo_sem_2019 = pd.read_csv(\"dados\\serie\\sem_2019-2_CA.csv\", encoding=\"UTF-8\", sep=\";\", skipinitialspace=True)\r\n",
    "    return pd.concat([df_serie_primeiro_sem_2019,df_serie_segundo_sem_2019])\r\n",
    "\r\n",
    "# carrega os dados de fiscalizações no dataframe\r\n",
    "def carregar_dados_de_fiscalizacoes():\r\n",
    "    df_fiscalizacoes = pd.read_csv(\"dados\\\\fiscalizacoes\\\\acoes-de-fiscalizacao.csv\", encoding=\"UTF-8\", sep=\";\", skipinitialspace=True, dtype=str)\r\n",
    "    return df_fiscalizacoes\r\n",
    "\r\n",
    "# carrega os dados de reclamações no dataframe\r\n",
    "def carregar_dados_de_reclamacoes():\r\n",
    "    df_reclamacoes = pd.read_csv(\"dados\\\\reclamacoes\\\\CRF2019 Dados Abertos.csv\", encoding=\"UTF-8\", sep=\";\", skipinitialspace=True, error_bad_lines=False, dtype=str)\r\n",
    "    return df_reclamacoes    \r\n",
    "\r\n",
    "# carrega os dados de multas de 2016 a 2019 no dataframe\r\n",
    "def carregar_dados_de_multas():\r\n",
    "    # O parâmetros skiprows foi necessário para ignorar as 4 primeiras linhas dos arquivo que possuem informações desnecessárias para a análise\r\n",
    "    df_multas = pd.read_csv(\"dados\\multas\\multas_2016_a_2019.csv\", encoding=\"UTF-8\", sep=\";\", skiprows=4, skipinitialspace=True)\r\n",
    "    return df_multas\r\n",
    "\r\n",
    "# carrega os vários arquivos PMQC que estão no diretório dados\\PMQC e concatena seus valores no dataframe final\r\n",
    "def carregar_dados_PMQC():\r\n",
    "    caminho = r'dados\\PMQC'\r\n",
    "    todos_os_arquivos = glob.glob(caminho + \"/*.csv\")\r\n",
    "    # inicializo um vetor para incluir cada dataframe do pandas que leu um arquivo .csv\r\n",
    "    li = []\r\n",
    "\r\n",
    "    for nome_arquivo in todos_os_arquivos:\r\n",
    "        df = pd.read_csv(nome_arquivo, encoding=\"UTF-8\", sep=\";\", usecols=['DataColeta','CnpjPosto','GrupoProduto','Uf','RegiaoPolitica','Ensaio','Resultado','Conforme'])\r\n",
    "        li.append(df)\r\n",
    "\r\n",
    "    df_PMQC = pd.concat(li)\r\n",
    "    return df_PMQC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe Fiscalizacoes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes = carregar_dados_de_fiscalizacoes()\r\n",
    "df_fiscalizacoes.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes['CNPJ/CPF']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes['CNPJ'] = df_fiscalizacoes['CNPJ/CPF'].str[0:2] + '.' + df_fiscalizacoes['CNPJ/CPF'].str[2:5] + '.' + df_fiscalizacoes['CNPJ/CPF'].str[5:8] + '/' + df_fiscalizacoes['CNPJ/CPF'].str[8:12] + '-' + df_fiscalizacoes['CNPJ/CPF'].str[12:14]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes['CNPJ']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes['Data DF'] = pd.to_datetime(df_fiscalizacoes['Data DF'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes = df_fiscalizacoes[df_fiscalizacoes['Data DF'] <= '2019-12-31']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes['Mes'] = pd.DatetimeIndex(df_fiscalizacoes['Data DF']).month"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes['Ocorrencias Fiscalizacoes'] = df_fiscalizacoes['Mes'].groupby(df_fiscalizacoes['CNPJ']).transform('count')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes = df_fiscalizacoes[['CNPJ','Ocorrencias Fiscalizacoes']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes.drop_duplicates(subset =['CNPJ'], inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe Reclamacoes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes = carregar_dados_de_reclamacoes()\r\n",
    "df_reclamacoes.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes['NumeroCNPJ']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes['NumeroCNPJ'] = df_reclamacoes['NumeroCNPJ'].apply(lambda x: '{0:0>14}'.format(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes['NumeroCNPJ']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes['CNPJ'] = df_reclamacoes['NumeroCNPJ'].str[0:2] + '.' + df_reclamacoes['NumeroCNPJ'].str[2:5] + '.' + df_reclamacoes['NumeroCNPJ'].str[5:8] + '/' + df_reclamacoes['NumeroCNPJ'].str[8:12] + '-' + df_reclamacoes['NumeroCNPJ'].str[12:14]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes['CNPJ']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes['Ocorrencias Reclamacoes'] = df_reclamacoes['NumeroCNPJ'].groupby(df_reclamacoes['CNPJ']).transform('count')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes = df_reclamacoes[['CNPJ', 'Ocorrencias Reclamacoes']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes.drop_duplicates(subset =['CNPJ'], inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_reclamacoes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe Multas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Carregando os dados das multas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas = carregar_dados_de_multas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando os dados do dataframe de multas carregado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Como a ligação entre os dataframes será pelo CNPJ, precisamos padronizá-lo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verificando como está o CNPJ no dataframe Multas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas['CNPJ/CPF']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adicionando zeros a esquerda na coluna cnpj"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas['CNPJ/CPF'] = df_multas['CNPJ/CPF'].apply(lambda x: '{0:0>14}'.format(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas['CNPJ/CPF']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Colocando o format de cnpj - 14 posições com xx.xxx.xxx/xxx-xx"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas['CNPJ'] = df_multas['CNPJ/CPF'].str[0:2] + '.' + df_multas['CNPJ/CPF'].str[2:5] + '.' + df_multas['CNPJ/CPF'].str[5:8] + '/' + df_multas['CNPJ/CPF'].str[8:12] + '-' + df_multas['CNPJ/CPF'].str[12:14]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cada linha do dataframe Multas deve possuir CNPJ unico."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Para isso, vamos verificar suas linhas duplicadas.\r\n",
    "#### Começamos atualizar o dataframe df_multas somente cos atributos que nos interessam (CNPJ e Valor da multa aplicada)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas = df_multas[['CNPJ','Valor da Multa Aplicada']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convertemos o tipo da coluna valor multa aplicada para float, trocando vírgula por ponto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas['Valor da Multa Aplicada'] = df_multas['Valor da Multa Aplicada'].str.replace(',', '.').astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Somamos o valor total da multa aplicada para uma nova coluna chamada Total multa"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas['Total multa'] = df_multas['Valor da Multa Aplicada'].groupby(df_multas['CNPJ']).transform('sum')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Removemos a coluna Valor da Multa Aplicada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas = df_multas[['CNPJ','Total multa']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Removemos as linhas duplicadas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas = df_multas.drop_duplicates()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando o resultado do dataframe df_multas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe PMQC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Carregando os dados do PMQC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC = carregar_dados_PMQC()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando os dados do dataframe PMQC carregado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando a coluna CnpjPosto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC['CnpjPosto']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Padronizando a coluna CNPJ, renomeando a coluna cnpjposto para CNPJ do dataframe PMQC, de forma a igualar com os outros dataframes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC.rename(columns={'CnpjPosto':'CNPJ'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Atualizando o tipo da coluna DataColeta para data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC['DataColeta'] = pd.to_datetime(df_PMQC['DataColeta'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criamos um nova coluna Mes a partir da data da coleta"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC['Mes'] = pd.DatetimeIndex(df_PMQC['DataColeta']).month"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removemos as linhas duplicadas, de forma que para cada CNPJ, no mês tenha apenas um tipo de Grupo Produto, considerando a coluna conformidade"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC.drop_duplicates(subset =['CNPJ','Mes','GrupoProduto'], inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removemos os atributos do dataframe df_PMQC, deixando somente os atributos CNPJ, MES, GrupoProduto e Conforme"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC = df_PMQC[['CNPJ','Mes','GrupoProduto','Conforme']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificamos o dataframe df_PMQC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataframe Serie Histórica de 2019"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Carregando os dados da serie histórica de 2019"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie = carregar_dados_serie_historica_2019()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Renomeando as colunas para UF e CNPJ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.rename(columns={'Estado - Sigla':'Uf','CNPJ da Revenda':'CNPJ'}, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Atualizamos o tipo da coluna Data Coleta para data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Data da Coleta'] = pd.to_datetime(df_serie['Data da Coleta'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criamos um nova coluna Mes a partir da data da coleta"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Mes'] = pd.DatetimeIndex(df_serie['Data da Coleta']).month"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formatamos os tipos das colunas 'Valor de Venda' e 'Valor de Compra' para float, alterando vírgula por ponto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Valor de Venda'] = df_serie['Valor de Venda'].str.replace(',', '.').astype(float)\r\n",
    "df_serie['Valor de Compra'] = df_serie['Valor de Compra'].str.replace(',', '.').astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Criamos a coluna GrupoProduto, onde vamos definir dentro dos produtos do dataframe serie a qual grupo de produtos ele pertence. Para começar, vamos importar a biblioteca numpy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vamos criar a lista de condições. Como temos 3 tipos de grupo de produtos, serão 3 condições de acordo com os produtos. Não vamos considerar o produto GNV, pois o mesmo não possui classificação de conforme"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Produto'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "condicoes = [\r\n",
    "    (df_serie['Produto'] == 'GASOLINA'),\r\n",
    "    (df_serie['Produto'] == 'ETANOL'),\r\n",
    "    (df_serie['Produto'] == 'DIESEL S10') | (df_serie['Produto'] == 'DIESEL'),\r\n",
    "    (df_serie['Produto'] == 'GNV')\r\n",
    "    ]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Criamos a lista de valores de GrupoProduto para cada condição"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_PMQC['GrupoProduto'].unique()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "valores = ['Gasolina', 'Etanol', 'Óleo Diesel', 'GNV']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Criamos a nova coluna GrupoProduto e usamos np.select para colocar o valor correto de acordo com as condições"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['GrupoProduto'] = np.select(condicoes, valores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removemos colunas desnecessárias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie = df_serie[['CNPJ','Mes','GrupoProduto','Uf','Valor de Venda','Valor de Compra','Bandeira']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualizamos o dataframe atualizado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando como ficou cada dataframe antes de juntá-los em um único dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_fiscalizacoes.info()\r\n",
    "df_reclamacoes.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_multas.info()\r\n",
    "df_PMQC.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formando um único dataframe df_serie para juntar com o dataframe df_PMQC pelo CNPJ, Mes e GrupoProduto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie = pd.merge(df_serie, df_PMQC, on=['CNPJ','Mes','GrupoProduto'], how='left' )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando o dataframe df_serie após a junção com o dataframe df_PMQC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formando um único dataframe df_serie para juntar com o dataframe df_multas pelo CNPJ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie = pd.merge(df_serie, df_multas, on='CNPJ', how='left' )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando o dataframe df_serie após a junção com df_multas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie = pd.merge(df_serie, df_reclamacoes, on='CNPJ', how='left')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie = pd.merge(df_serie, df_fiscalizacoes, on='CNPJ', how='left')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Para a nova coluna Multado incluímos a informação se existe multa ou não"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Multado'] = np.where(df_serie['Total multa'] > 0, 'Sim', 'Não')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Para a nova coluna Reclamado incluímos a informação se existe reclamação ou não."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Reclamado'] = np.where(df_serie['Ocorrencias Reclamacoes'] > 0, 'Sim', 'Não')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Por fim, criamos uma nova coluna 'Fiscalizado' e incluímos a informação se já foi fiscalizado ou não."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Fiscalizado'] = np.where(df_serie['Ocorrencias Fiscalizacoes'] > 0, 'Sim', 'Não')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Removendo as linhas da coluna Conforme igual a NaN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.dropna(subset = [\"Conforme\"], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Para nossa análise, não podemos ter atributos vazios \"NaN\", logo precisamos eliminar as linhas da coluna Valor da compra que estão nesta situação"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.dropna(subset = [\"Valor de Compra\"], inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Com os novos atributos, podemos eliminar os atributos \"Ocorrencias Fiscalizacoes\" e \"Ocorrencias Reclamacoes\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.drop(['Ocorrencias Fiscalizacoes','Ocorrencias Reclamacoes','Total multa'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando valores vazios"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agora temos nosso dataframe pronto para realizar a análise de Machine Learn (todos os atributos vazios ou com NaN foram removidos)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Análise da correlação entre os Valores de Compra e Venda"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Valor de Venda'].corr(df_serie['Valor de Compra'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie_gasolina = df_serie[['Mes','GrupoProduto','Uf','Valor de Venda','Valor de Compra','Bandeira','Conforme','Multado','Reclamado','Fiscalizado']]\r\n",
    "df_serie_gasolina = df_serie_gasolina[df_serie_gasolina['GrupoProduto'] == 'Gasolina']\r\n",
    "df_serie_gasolina.nlargest(5,'Valor de Venda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie_gasolina.nsmallest(5,'Valor de Venda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sb\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import pyplot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Verificando outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = sb.boxplot(x=df_serie_gasolina[\"Valor de Venda\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = sb.boxplot(x=df_serie_gasolina[\"Valor de Compra\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grafico = df_serie_gasolina[['Valor de Compra','Valor de Venda','Mes']].groupby(df_serie_gasolina['Mes']).mean().plot(\r\n",
    "                            title=\"Variação do preço médio da Gasolina\",\r\n",
    "                            x=\"Mes\",\r\n",
    "                            y=['Valor de Compra','Valor de Venda'],figsize=(14,8))\r\n",
    "grafico.set_xlabel(\"Mês de 2019\")\r\n",
    "grafico.set_ylabel(\"Valor em R$\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Conforme'].groupby(df_serie['Uf']).value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Reclamado'].groupby(df_serie['Uf']).value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Multado'].groupby(df_serie['Uf']).value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie_multado_sim = df_serie[df_serie[\"Multado\"] == 'Sim']\r\n",
    "df_serie_multado_sim = df_serie_multado_sim['Multado'].groupby(df_serie_multado_sim['Uf']).value_counts().sort_values(ascending=False)\r\n",
    "df_serie_multado_sim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grafico = df_serie_multado_sim.sort_values(ascending=False).head(5).plot(kind='bar',\r\n",
    "                                    figsize=(12,8),\r\n",
    "                                    title=\"5 estados do país com maior quantidade de multas\")\r\n",
    "grafico.set_xlabel(\"UF\")\r\n",
    "grafico.set_ylabel(\"Ocorrências de multas\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analisando a coluna Fiscalizado"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Fiscalizado'].groupby(df_serie['Uf']).value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie_fiscalizado_sim = df_serie[df_serie[\"Fiscalizado\"] == 'Sim']\r\n",
    "df_serie_fiscalizado_sim = df_serie_fiscalizado_sim['Fiscalizado'].groupby(df_serie_fiscalizado_sim['Uf']).value_counts()\r\n",
    "df_serie_fiscalizado_sim.sort_values(ascending=False).head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grafico = df_serie_fiscalizado_sim.sort_values(ascending=False).head(5).plot(kind='bar',\r\n",
    "                                    figsize=(14,8),\r\n",
    "                                    title=\"5 estados do país com maior quantidade de fiscalizações\")\r\n",
    "grafico.set_xlabel(\"UF\")\r\n",
    "grafico.set_ylabel(\"Ocorrências de fiscalizações\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grafico = df_serie_fiscalizado_sim.sort_values(ascending=True).head(5).plot(kind='bar',\r\n",
    "                                    figsize=(14,8),\r\n",
    "                                    title=\"5 estados do país com menor quantidade de fiscalizações\")\r\n",
    "grafico.set_xlabel(\"UF\")\r\n",
    "grafico.set_ylabel(\"Ocorrências de fiscalizações\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Medidas estatísticas do DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie.describe(include='all')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_serie['Fiscalizado'].value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Em forma de gráfico de barras"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ax = sb.countplot(x=\"Fiscalizado\", data=df_serie)\r\n",
    "\r\n",
    "coluna_alvo = df_serie.Fiscalizado.value_counts()\r\n",
    "print('Não:', coluna_alvo[0])\r\n",
    "print('Sim:', coluna_alvo[1])\r\n",
    "print('Proporção:', round(coluna_alvo[1] / coluna_alvo[0], 2), ': 1')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Realizando a importação das bibliotecas necessárias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criamos as variáveis que serão usadas como previsores da classificacao e a classe alvo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilizamos o labelenconder somente para as colunas com atributos categóricos, transformando-os em numéricos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Os atributos Mes, Valor de Venda e Valor de Compra não precisam ser transformados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "le = LabelEncoder()\r\n",
    "\r\n",
    "atributos = df_serie.iloc[:,0:10].values\r\n",
    "atributos[:,0] = le.fit_transform(atributos[:,0])  \r\n",
    "atributos[:,2] = le.fit_transform(atributos[:,2])  \r\n",
    "atributos[:,3] = le.fit_transform(atributos[:,3])  \r\n",
    "atributos[:,6] = le.fit_transform(atributos[:,6])  \r\n",
    "atributos[:,7] = le.fit_transform(atributos[:,7])  \r\n",
    "atributos[:,8] = le.fit_transform(atributos[:,8])  \r\n",
    "atributos[:,9] = le.fit_transform(atributos[:,9])  \r\n",
    "\r\n",
    "classe_alvo = df_serie.iloc[:,10].values  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Realizamos a divisão do dataframe entre treinamento e teste (na proporção de 20% para teste e 80% para treinamento)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_treinamento, X_teste, Y_treinamento, Y_teste =  train_test_split(atributos, classe_alvo, test_size = 0.2, random_state = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo NAIVE BAYES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criamos do modelo Gaussian Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinamos o modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classificador_nb = GaussianNB()\r\n",
    "classificador_nb.fit(X_treinamento, Y_treinamento)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Com as predições podemos usar o dataframe separado para o teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predicao_nb = classificador_nb.predict(X_teste)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizamos as predições usando o dataframe separado para o teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predicao_nb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geramos a matriz de confusão"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confusao_nb = confusion_matrix(Y_teste, predicao_nb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(confusao_nb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizando a matrix de confusão"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cmd_nb = ConfusionMatrixDisplay(confusao_nb, display_labels=classificador_nb.classes_).plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "relatorio_nb = classification_report(Y_teste, predicao_nb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(relatorio_nb)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validação cruzada para o modelo Naive bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_score\r\n",
    "\r\n",
    "validacao_nb = cross_val_score(classificador_nb, atributos, classe_alvo, scoring='accuracy', cv=5)\r\n",
    "print(validacao_nb.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo Arvore de decisao"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.tree import plot_tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Criamos e treinamos o modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classificador_arvore = DecisionTreeClassifier(random_state = 1) \r\n",
    "classificador_arvore.fit(X_treinamento,Y_treinamento)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizamos a árvore de decisão"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(14,8))\r\n",
    "plot_tree(classificador_arvore, max_depth=5, filled=True, rounded=True)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predições com os registros de teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predicao_arvore = classificador_arvore.predict(X_teste)\r\n",
    "print(predicao_arvore)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Matriz de confusão e cálculo da acurácia"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confusao_arvore = confusion_matrix(Y_teste, predicao_arvore)\r\n",
    "print(confusao_arvore)\r\n",
    "cmd_arvore = ConfusionMatrixDisplay(confusao_arvore, display_labels=classificador_arvore.classes_).plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizando o relatório da matriz de confusão da arvore de decisão"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "relatorio_arvore = classification_report(Y_teste, predicao_arvore)\r\n",
    "print(relatorio_arvore)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validação cruzada para o classificador arvore"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validacao_arvore = cross_val_score(classificador_arvore, atributos, classe_alvo, scoring='accuracy', cv=5)\r\n",
    "print(validacao_arvore.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "classificador_rf = RandomForestClassifier()\r\n",
    "classificador_rf.fit(X_treinamento, Y_treinamento)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Realizamos a predição do modelo nos dados de teste"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predicao_rf = classificador_rf.predict(X_teste)\r\n",
    "print(predicao_rf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "confusao_rf = confusion_matrix(Y_teste, predicao_rf)\r\n",
    "print(confusao_rf)\r\n",
    "cmd_rf = ConfusionMatrixDisplay(confusao_rf, display_labels=classificador_rf.classes_).plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "relatorio_rf = classification_report(Y_teste, predicao_rf)\r\n",
    "print(relatorio_rf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validação cruzada do classificador Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validacao_rf = cross_val_score(classificador_rf, atributos, classe_alvo, scoring='accuracy', cv=5)\r\n",
    "print(validacao_rf.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo SVM (Support Vector Machine)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import svm\r\n",
    "\r\n",
    "classificador_svm = svm.SVC(gamma='auto')\r\n",
    "classificador_svm.fit(X_treinamento, Y_treinamento)\r\n",
    "predicao_svm = classificador_svm.predict(X_teste)\r\n",
    "confusao_svm = confusion_matrix(Y_teste, predicao_svm)\r\n",
    "print(confusao_svm)\r\n",
    "cmd_svm = ConfusionMatrixDisplay(confusao_svm, display_labels=classificador_svm.classes_).plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "relatorio_svm = classification_report(Y_teste, predicao_svm)\r\n",
    "print(relatorio_svm)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validacao_svm = cross_val_score(classificador_svm, atributos, classe_alvo, scoring='accuracy', cv=5)\r\n",
    "print(validacao_svm.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinando o KNN - Valor inicial padrão"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "classificador_knn = KNeighborsClassifier()\r\n",
    "classificador_knn.fit(X_treinamento, Y_treinamento)\r\n",
    "predicao_knn = classificador_knn.predict(X_teste)\r\n",
    "confusao_knn = confusion_matrix(Y_teste, predicao_knn)\r\n",
    "print(confusao_knn)\r\n",
    "cmd_knn = ConfusionMatrixDisplay(confusao_knn, display_labels=classificador_knn.classes_).plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "relatorio_knn = classification_report(Y_teste, predicao_knn)\r\n",
    "print(relatorio_knn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Avaliamos o desempenho do KNN com validação cruzada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Faz a validação cruzada com 5 folds e ao final exibe a média da acurácia"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validacao_knn = cross_val_score(classificador_knn, atributos, classe_alvo, scoring='accuracy', cv=5)\r\n",
    "print(validacao_knn.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vamos avaliar o desempenho do modelo com outros k vizinhos (1 a 10)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Treinando o KNN - Valor k = 1 a 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for k in range(1, 11):\r\n",
    "    classificador_knn = KNeighborsClassifier(n_neighbors = k)\r\n",
    "    classificador_knn.fit(X_treinamento, Y_treinamento)\r\n",
    "    validacao_knn = cross_val_score(classificador_knn, atributos, classe_alvo, scoring='accuracy', cv=5)\r\n",
    "    print('Validação cruzada para a acurácia do modelo knn sendo k = ' + str(k) + ' -> ' + str(validacao_knn.mean()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Agora com o classificador_knn recebendo o modelo com k = 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classificador_knn_1 = KNeighborsClassifier(n_neighbors = 1)\r\n",
    "classificador_knn_1.fit(X_treinamento, Y_treinamento)\r\n",
    "predicao_knn_1 = classificador_knn_1.predict(X_teste)\r\n",
    "confusao_knn_1 = confusion_matrix(Y_teste, predicao_knn_1)\r\n",
    "print(confusao_knn_1)\r\n",
    "cmd_knn_1 = ConfusionMatrixDisplay(confusao_knn_1, display_labels=classificador_knn_1.classes_).plot()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "relatorio_knn_1 = classification_report(Y_teste, predicao_knn_1)\r\n",
    "print(relatorio_knn_1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aplicando reamostragem com o SMOTE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from imblearn.over_sampling import SMOTE\r\n",
    "\r\n",
    "atributos_re = atributos\r\n",
    "classe_alvo_re = classe_alvo\r\n",
    "\r\n",
    "smote = SMOTE(random_state=1)\r\n",
    "atributos_re, classe_alvo_re = smote.fit_resample(atributos_re, classe_alvo_re)\r\n",
    "sb.countplot(x=classe_alvo_re)\r\n",
    "\r\n",
    "X_treinamento_re, X_teste_re, Y_treinamento_re, Y_teste_re =  train_test_split(atributos_re, classe_alvo_re, test_size = 0.2, random_state = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo Naive Bayes com reamostragem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classificador_nb_re = GaussianNB()\r\n",
    "classificador_nb_re.fit(X_treinamento_re, Y_treinamento_re)\r\n",
    "predicao_nb_re = classificador_nb_re.predict(X_teste_re)\r\n",
    "confusao_nb_re = confusion_matrix(Y_teste_re, predicao_nb_re)\r\n",
    "print(confusao_nb_re)\r\n",
    "cmd_nb_re = ConfusionMatrixDisplay(confusao_nb_re, display_labels=classificador_nb_re.classes_).plot()\r\n",
    "relatorio_nb_re = classification_report(Y_teste_re, predicao_nb_re)\r\n",
    "print(relatorio_nb_re)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validacao_nb_re = cross_val_score(classificador_nb_re, atributos_re, classe_alvo_re, scoring='accuracy', cv=5)\r\n",
    "print(validacao_nb_re.mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modelo Random Forest com Reamostragem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classificador_rf_re = RandomForestClassifier()\r\n",
    "classificador_rf_re.fit(X_treinamento_re, Y_treinamento_re)\r\n",
    "predicao_rf_re = classificador_rf_re.predict(X_teste_re)\r\n",
    "confusao_rf_re = confusion_matrix(Y_teste_re, predicao_rf_re)\r\n",
    "print(confusao_rf_re)\r\n",
    "cmd_rf_re = ConfusionMatrixDisplay(confusao_rf_re, display_labels=classificador_rf_re.classes_).plot()\r\n",
    "relatorio_rf_re = classification_report(Y_teste_re, predicao_rf_re)\r\n",
    "print(relatorio_rf_re)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validacao_rf_re = cross_val_score(classificador_rf_re, atributos_re, classe_alvo_re, scoring='accuracy', cv=5)\r\n",
    "print(validacao_rf_re.mean())"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "interpreter": {
   "hash": "9411698793c381aca098971598ff56530d821e0559c1190497e22ec0ac628f49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}